{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, BatchNormalization, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras.applications import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dice_coefficient function\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    return (2.0 * intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define la clase del generador de datos\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, imagenes, heatmaps, batch_size=32):\n",
    "        self.imagenes = imagenes\n",
    "        self.heatmaps = heatmaps\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.imagenes))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.imagenes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = (index + 1) * self.batch_size\n",
    "        batch_x = self.imagenes[start:end]\n",
    "        batch_y = self.heatmaps[start:end]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de los archivos\n",
    "imagenes_train_path = r\"D:\\Tec\\7mo Smestre\\Inteligencia Artificial II\\Reto\\Datos\\Arrays Heatmaps\\train\\trainimagenes_originales_train.npy\"\n",
    "imagenes_val_path = r\"D:\\Tec\\7mo Smestre\\Inteligencia Artificial II\\Reto\\Datos\\Arrays Heatmaps\\val\\valimagenes_originales_val.npy\"\n",
    "imagenes_test_path = r\"D:\\Tec\\7mo Smestre\\Inteligencia Artificial II\\Reto\\Datos\\Arrays Heatmaps\\test\\trainimagenes_originales_test.npy\"\n",
    "heatmaps_train_path = r\"D:\\Tec\\7mo Smestre\\Inteligencia Artificial II\\Reto\\Datos\\Arrays Heatmaps\\train\\trainheatmaps_train.npy\"\n",
    "heatmaps_val_path = r\"D:\\Tec\\7mo Smestre\\Inteligencia Artificial II\\Reto\\Datos\\Arrays Heatmaps\\val\\valheatmaps_val.npy\"\n",
    "heatmaps_test_path = r\"D:\\Tec\\7mo Smestre\\Inteligencia Artificial II\\Reto\\Datos\\Arrays Heatmaps\\test\\trainheatmaps_test.npy\"\n",
    "\n",
    "# Cargar los archivos\n",
    "imagenes_train = np.load(imagenes_train_path)\n",
    "heatmaps_train = np.load(heatmaps_train_path)\n",
    "imagenes_val = np.load(imagenes_val_path)\n",
    "heatmaps_val = np.load(heatmaps_val_path)\n",
    "imagenes_test = np.load(imagenes_test_path)\n",
    "heatmaps_test = np.load(heatmaps_test_path)\n",
    "\n",
    "# Convertir uint8 tensor a float32 y normalizar imágenes\n",
    "imagenes_train = imagenes_train.astype('float32') / 255.0\n",
    "imagenes_val = imagenes_val.astype('float32') / 255.0\n",
    "imagenes_test = imagenes_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model_1/dense_5/MatMul/MatMul_1' defined at (most recent call last):\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3046, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3101, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3488, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\vhae1\\AppData\\Local\\Temp\\ipykernel_5040\\1808441498.py\", line 41, in <module>\n      history = model.fit(train_generator, epochs=30, validation_data=val_generator, callbacks=[checkpoint])\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_1/dense_5/MatMul/MatMul_1'\nOOM when allocating tensor with shape[2048,87808] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model_1/dense_5/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_27008]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32md:\\Tec\\7mo Smestre\\Inteligencia Artificial II\\Reto\\Codigo\\Entrenamiento_heatmaps_3.0.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/7mo%20Smestre/Inteligencia%20Artificial%20II/Reto/Codigo/Entrenamiento_heatmaps_3.0.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m test_generator \u001b[39m=\u001b[39m DataGenerator(imagenes_test, heatmaps_test, batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/7mo%20Smestre/Inteligencia%20Artificial%20II/Reto/Codigo/Entrenamiento_heatmaps_3.0.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tec/7mo%20Smestre/Inteligencia%20Artificial%20II/Reto/Codigo/Entrenamiento_heatmaps_3.0.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_generator, callbacks\u001b[39m=\u001b[39;49m[checkpoint])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/7mo%20Smestre/Inteligencia%20Artificial%20II/Reto/Codigo/Entrenamiento_heatmaps_3.0.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Evaluar el modelo en datos de prueba utilizando el generador\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/7mo%20Smestre/Inteligencia%20Artificial%20II/Reto/Codigo/Entrenamiento_heatmaps_3.0.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m test_loss, test_dice_score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_generator)\n",
      "File \u001b[1;32mc:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model_1/dense_5/MatMul/MatMul_1' defined at (most recent call last):\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3046, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3101, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3488, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\vhae1\\AppData\\Local\\Temp\\ipykernel_5040\\1808441498.py\", line 41, in <module>\n      history = model.fit(train_generator, epochs=30, validation_data=val_generator, callbacks=[checkpoint])\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\vhae1\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_1/dense_5/MatMul/MatMul_1'\nOOM when allocating tensor with shape[2048,87808] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model_1/dense_5/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_27008]"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo VGG16 preentrenado\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(112, 112, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Agregar capas personalizadas al modelo\n",
    "x = base_model.output\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Regularización L2\n",
    "x = Flatten()(x)\n",
    "x = Dense(2048, activation='relu', kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2048, activation='relu', kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(112 * 112 * 7, activation='sigmoid')(x)\n",
    "output_layer = Reshape((112, 112, 7))(x)\n",
    "\n",
    "# Crear el modelo completo\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "# Configurar el checkpoint para guardar el mejor modelo\n",
    "checkpoint = ModelCheckpoint(\"mejor_modelo.h5\", monitor='val_dice_coefficient', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=[dice_coefficient])\n",
    "\n",
    "# Crear instancias del generador de datos para entrenamiento y validación\n",
    "train_generator = DataGenerator(imagenes_train, heatmaps_train, batch_size=16)\n",
    "val_generator = DataGenerator(imagenes_val, heatmaps_val, batch_size=16)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(train_generator, epochs=30, validation_data=val_generator, callbacks=[checkpoint])\n",
    "\n",
    "# Evaluar el modelo en datos de prueba\n",
    "test_loss, test_dice_score = model.evaluate(imagenes_test, heatmaps_test)\n",
    "print(f'Loss en datos de prueba: {test_loss}')\n",
    "print(f'DICE SCORE en datos de prueba: {test_dice_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
